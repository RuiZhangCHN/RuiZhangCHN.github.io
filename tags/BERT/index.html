<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><title>标签: BERT - 张睿 | 智能对话、AIGC、自然语言处理</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="张睿 | 智能对话、AIGC、自然语言处理"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="张睿 | 智能对话、AIGC、自然语言处理"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="website"><meta property="og:title" content="张睿 | 智能对话、AIGC、自然语言处理"><meta property="og:url" content="http://ruizhangchn.github.io/"><meta property="og:site_name" content="张睿 | 智能对话、AIGC、自然语言处理"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://ruizhangchn.github.io/img/og_image.png"><meta property="article:author" content="Rui Zhang"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://ruizhangchn.github.io/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://ruizhangchn.github.io"},"headline":"张睿 | 智能对话、AIGC、自然语言处理","image":["http://ruizhangchn.github.io/img/og_image.png"],"author":{"@type":"Person","name":"Rui Zhang"},"publisher":{"@type":"Organization","name":"张睿 | 智能对话、AIGC、自然语言处理","logo":{"@type":"ImageObject","url":"http://ruizhangchn.github.io/img/logo.svg"}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="张睿 | 智能对话、AIGC、自然语言处理" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">博客</a><a class="navbar-item" href="/papers">论文&amp;项目</a><a class="navbar-item" href="/about">关于我</a></div><div class="navbar-end"><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">标签</a></li><li class="is-active"><a href="#" aria-current="page">BERT</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2018-11-21T15:19:39.000Z" title="2018/11/21 下午11:19:39">2018-11-21</time>发表</span><span class="level-item"><time dateTime="2023-02-20T15:29:09.053Z" title="2023/2/20 下午11:29:09">2023-02-20</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a></span><span class="level-item">13 分钟读完 (大约1915个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/11/21/BERT%E6%A8%A1%E5%9E%8BFine-tuning%E5%88%9D%E6%8E%A2/">BERT模型Fine-tuning初探</a></p><div class="content"><p>使用BERT模型进行Fine-tuning分类器。</p>
<h2 id="BERT环境搭建"><a href="#BERT环境搭建" class="headerlink" title="BERT环境搭建"></a>BERT环境搭建</h2><p>首先需要在服务器中创建自己的虚拟环境，如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pyenv virtualenv 3.6.6 muenn25</span><br></pre></td></tr></table></figure>
<p>切换到虚拟环境中：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pyenv activate muenn25</span><br></pre></td></tr></table></figure>
<p>下载BERT项目到指定目录：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/google-research/bert.git /home/zr/bert_tf</span><br></pre></td></tr></table></figure>
<p>跳转到该目录：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /home/zr/bert_tf</span><br></pre></td></tr></table></figure>
<p>下载官方提供的预训练好的bert模型，存储到自己的模型路径。（我的是：&#x2F;home&#x2F;zr&#x2F;bert_trained_models&#x2F;uncased_L-12_H-768_A-12)</p>
<h2 id="BERT模型修改"><a href="#BERT模型修改" class="headerlink" title="BERT模型修改"></a>BERT模型修改</h2><p>如果新的分类任务也是单标签分类的话，只需要基于run_classifier.py函数下的DataProcessor类定义一个自己的数据处理器。<br>我使用了SemEval的数据进行了简单实验，写了一个新的数据处理器类如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">class SemProcessor(DataProcessor):</span><br><span class="line">    &quot;&quot;&quot;Processor for the SemEval data set.&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def get_train_examples(self, data_dir):</span><br><span class="line">        return self._create_examples(</span><br><span class="line">            self._read_tsv(os.path.join(data_dir, &#x27;train.tsv&#x27;)), &#x27;train&#x27;)</span><br><span class="line"></span><br><span class="line">    def get_dev_examples(self, data_dir):</span><br><span class="line">        return self._create_examples(</span><br><span class="line">            self._read_tsv(os.path.join(data_dir, &#x27;dev.tsv&#x27;)), &#x27;dev&#x27;)</span><br><span class="line"></span><br><span class="line">    def get_test_examples(self, data_dir):</span><br><span class="line">        return self._create_examples(</span><br><span class="line">            self._read_tsv(os.path.join(data_dir, &#x27;test.tsv&#x27;)), &#x27;test&#x27;)</span><br><span class="line"></span><br><span class="line">    def get_labels(self):</span><br><span class="line">        return [&quot;others&quot;, &quot;happy&quot;, &quot;sad&quot;, &quot;angry&quot;]</span><br><span class="line"></span><br><span class="line">    def _create_examples(self, lines, set_type):</span><br><span class="line">        examples = []</span><br><span class="line">        for (i, line) in enumerate(lines):</span><br><span class="line">            guid = line[0]</span><br><span class="line">            text_a = tokenization.convert_to_unicode(line[1])</span><br><span class="line">            text_b = None</span><br><span class="line">            if set_type != &#x27;test&#x27;:</span><br><span class="line">                label = tokenization.convert_to_unicode(line[2])</span><br><span class="line">            else:</span><br><span class="line">                label = &quot;others&quot;</span><br><span class="line">            examples.append(</span><br><span class="line">                InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))</span><br><span class="line">        return examples</span><br></pre></td></tr></table></figure>

<p>需要注意的是，对于预测时候的test数据集，同样也要给他的label赋一个值，不然模型运行过程中会出错。同时，main函数中也要增加相应的dataProcessor信息：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">processors = &#123;</span><br><span class="line">      &quot;cola&quot;: ColaProcessor,</span><br><span class="line">      &quot;mnli&quot;: MnliProcessor,</span><br><span class="line">      &quot;mrpc&quot;: MrpcProcessor,</span><br><span class="line">      &quot;xnli&quot;: XnliProcessor,</span><br><span class="line">      &quot;sem&quot;: SemProcessor,        # 加入自定义的Processor</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<h2 id="基于BERT的分类模型的运行"><a href="#基于BERT的分类模型的运行" class="headerlink" title="基于BERT的分类模型的运行"></a>基于BERT的分类模型的运行</h2><p>首先设置预训练好的模型路径BERT_BASE_DIR：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export MUENN_BERT_BASE_DIR=/home/zr/bert_trained_models/uncased_L-12_H-768_A-12</span><br></pre></td></tr></table></figure>
<p>设置数据路径GLUE_DIR:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export MUENN_GLUE_DIR=/home/zr/bert_data</span><br></pre></td></tr></table></figure>
<p>运行模型。其中每一个参数都需要按照自己的实际情况修改：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">python run_classifier.py \</span><br><span class="line">--task_name=Sem \</span><br><span class="line">--do_train=true \</span><br><span class="line">--do_eval=true \</span><br><span class="line">--data_dir=$MUENN_GLUE_DIR/SemEval \</span><br><span class="line">--vocab_file=$MUENN_BERT_BASE_DIR/vocab.txt \</span><br><span class="line">--bert_config_file=$MUENN_BERT_BASE_DIR/bert_config.json \</span><br><span class="line">--init_checkpoint=$MUENN_BERT_BASE_DIR/bert_model.ckpt \</span><br><span class="line">--max_seq_length=128 \</span><br><span class="line">--train_batch_size=32 \</span><br><span class="line">--learning_rate=2e-5 \</span><br><span class="line">--num_train_epochs=3.0 \</span><br><span class="line">--output_dir=/home/zr/bert_tf/sem_output/ \</span><br><span class="line">--do_predict=true </span><br></pre></td></tr></table></figure>

<h2 id="run-classifier代码浅析"><a href="#run-classifier代码浅析" class="headerlink" title="run_classifier代码浅析"></a>run_classifier代码浅析</h2><p>BERT源码中run_classifier.py文件是基于BERT模型进行Fine-tuning的核心部分。</p>
<p>其中，如果需要将模型改为自己的分类模型，基本上只需要修改DataProcessor部分的内容。如果需要修改成其他特殊类型的分类器（如，多类标分类，需要采用sigmoid激活函数）则还需要修改create_model方法中的内容。</p>
<p>以下是该代码文件的详细解析。</p>
<h3 id="0-main函数-Line-741-903"><a href="#0-main函数-Line-741-903" class="headerlink" title="0.main函数 [Line 741-903]"></a>0.main函数 [Line 741-903]</h3><ol>
<li>定义data_processor列表。共有四种processor，对应四种不同数据集: ｛Cola、Mnli、Mrpc、Xnli｝。参见”1.DataProcessor数据处理器”。 [Line 744-749]</li>
<li>判断FLAGS.do_train和FLAGS.do_eval是否至少有一个为True。 [Line 751-753]</li>
<li>从Config文件读取配置信息。 [Line: 755]</li>
<li>判断FLAGS.max_seq_length是否大于config.max_position_embedding，若是则报错（因为无法进行位置Embedding。 [Line: 757-761]</li>
<li>创建输出路径。 [Line: 763]</li>
<li>获取task_name，根据task_name获取processor和label_list。 [Line: 765-772]</li>
<li>创建分词器tokenizer，这里采用FullTokenizer，其他分词器还有BasicTokenizer和WordpieceTokenizer等。[Line: 774-775]</li>
<li>设置tpu相关参数。我们没有tpu，可以忽略。(注：往下几行代码会调用tf.contrib.tpu包下的内容，如果检测到运行环境没有tpu，会自动降级到GPU或者CPU环境运行。) [Line: 777-791]</li>
<li>若FLAGS.do_train参数为True，初始化训练数据train_examples、训练步数num_train_steps和暖启动步数num_warmup_steps。 [Line: 796-800]</li>
<li>调用model_fn_builder函数构建模型，获得一个TPUEstimatorSpec对象。参见”3.model_fn_builder”。 [Line: 802-810]</li>
<li>使用上一步获得的TPUEstimatorSpec对象构建一个TPUEstimator对象，这个对象相当于模型实例。 [Line: 814-820]</li>
<li>若当前为train模式，步骤如下：(a)定义train_file文件为输出路径下的”train.tf_record”文件；(b)调用file_based_convert_examples_to_features函数将InputExample类型数据写入train_file文件；(c)调用file_based_input_fn_builder从train_file文件读取数据，用于训练。[Line: 822-835]</li>
<li>若为eval或predict模式，步骤与train相似，同样是先持久化InputExample数据到本地文件再读取，然后运行。[Line: 837-903]</li>
</ol>
<h3 id="1-DataProcessor数据处理器-Line-158-185"><a href="#1-DataProcessor数据处理器-Line-158-185" class="headerlink" title="1.DataProcessor数据处理器 [Line 158-185]"></a>1.DataProcessor数据处理器 [Line 158-185]</h3><p>将句子分类数据集进行数据转换的基类。</p>
<p><strong>get_train_examples(data_dir) [Line 161-163]</strong><br>从给定路径读取训练集，转换为InputExample类型的数据。</p>
<p><strong>get_dev_examples(data_dir) [Line 165-167]</strong><br>从给定路径读取验证集，转换为InputExample类型的数据。</p>
<p><strong>get_test_examples(data_dir) [Line 169-171]</strong><br>从给定路径读取测试集，转换为InputExample类型的数据。</p>
<p><strong>get_labels() [Line 173-175]</strong><br>获取该数据集的标签列表。</p>
<p><strong>_read_tsv(cls, input_file, quotechar) [Line 178-185]</strong><br>读取一个用“\t”分割的csv文件。</p>
<h4 id="1-1-XnliProcessor-Xnli数据处理器-Line-188-233"><a href="#1-1-XnliProcessor-Xnli数据处理器-Line-188-233" class="headerlink" title="1.1 XnliProcessor Xnli数据处理器 [Line 188-233]"></a>1.1 XnliProcessor Xnli数据处理器 [Line 188-233]</h4><p>处理XNLI数据集（从init函数看应该是可以处理其他语种，如中文”zh”）。分类标签类别分别是[“contradiction”矛盾, “entailment”蕴含, “neutral”中性]，应该是类似于两个句子间关系的分类任务。</p>
<h4 id="1-2-MnliProcessor-Mnli数据处理器-Line-236-274"><a href="#1-2-MnliProcessor-Mnli数据处理器-Line-236-274" class="headerlink" title="1.2 MnliProcessor Mnli数据处理器 [Line 236-274]"></a>1.2 MnliProcessor Mnli数据处理器 [Line 236-274]</h4><p>处理MultiNLI数据集，应该处理是GLUE版本数据集的数据，分类标签同样是[“contradiction”, “entailment”, “neutral”]。</p>
<h4 id="1-3-MrpcProcessor-Mrpc数据处理器-Line-277-314"><a href="#1-3-MrpcProcessor-Mrpc数据处理器-Line-277-314" class="headerlink" title="1.3 MrpcProcessor Mrpc数据处理器 [Line 277-314]"></a>1.3 MrpcProcessor Mrpc数据处理器 [Line 277-314]</h4><p>处理MRPC数据集，分类标签是[“0”, “1”]。</p>
<h4 id="1-4-ColaProcessor-Cola数据处理器-Line-317-355"><a href="#1-4-ColaProcessor-Cola数据处理器-Line-317-355" class="headerlink" title="1.4 ColaProcessor Cola数据处理器 [Line 317-355]"></a>1.4 ColaProcessor Cola数据处理器 [Line 317-355]</h4><p>处理CoLA数据集，分类标签同样是[“0”, “1”]。</p>
<h3 id="2-model-fn-builder模型函数创建器-Line-586-666"><a href="#2-model-fn-builder模型函数创建器-Line-586-666" class="headerlink" title="2. model_fn_builder模型函数创建器 [Line: 586-666]"></a>2. model_fn_builder模型函数创建器 [Line: 586-666]</h3><p>该方法实质上返回了一个函数model_fn(features, labels, mode, params)。这个函数的运行过程如下：</p>
<ol>
<li>从feature中获取四个变量：input_ids、input_mask、segment_ids和label_ids。 [Line: 598-601]</li>
<li>判断当前模型是否为训练模式。 [Line: 603]</li>
<li>调用create_model函数创建模型。参见”4.create_model创建模型” [Line: 605-607]</li>
<li>尝试从已经训练好的checkpoint加载模型。 [Line: 609-623]</li>
<li>在日志中打印可以训练的参数。[Line: 625-631]</li>
<li>如果mode为train，首先定义训练优化器train_op，然后返回一个TPUEstimatorSpec对象output_spec。[Line: 634-643]</li>
<li>如果mode为eval，首先定义评价函数metric_fn，然后定义评价指标参数eval_metrics，最终返回一个TPUEstimatorSpec对象output_spec。 [Line: 644-660]</li>
<li>若mode不为上述两种，则直接返回一个TPUEstimatorSpec对象output_spec。[Line: 661-663]</li>
</ol>
<h3 id="3-create-model创建模型-Line-541-583"><a href="#3-create-model创建模型-Line-541-583" class="headerlink" title="3.create_model创建模型 [Line: 541-583]"></a>3.create_model创建模型 [Line: 541-583]</h3><p>该方法包含以下步骤：</p>
<ol>
<li>构建一个modeling.BertModel对象。 [Line: 544-550]</li>
<li>获取pooled_output（即最后一个输出层的特殊分类token的结果。如果需要输出序列的结果，如进行序列标注任务，则需要使用get_sequence_output方法） [Line: 557]</li>
<li>定义hidden_size、output_weights和output_bias。这几个变量是用于构建一个新的分类层作Fine-tuning。 [Line: 559-566]</li>
<li>对output_layer结果进行Dropout。 [Line: 569-571]</li>
<li>进行最后一个全连接层的计算。 [Line: 573-576]</li>
<li>计算loss。 [Line: 578-581]</li>
<li>返回loss平均损失、per_example_loss逐个样例的损失、logits输出层原始结果、probabilities进行归一化之后的结果。[Line: 583]</li>
</ol>
</div></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/imgs/zhang2.jpg" alt="张睿"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">张睿</p><p class="is-size-6 is-block">博士 / 算法研究员 / 高级工程师</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>华为技术有限公司·深圳</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">15</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">4</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">22</p></a></div></div></nav><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/RuiZhangCHN"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Google Scholar" href="https://scholar.google.com/citations?user=Cn70dv8AAAAJ"><i class="fab fa-google"></i></a></div></div></div><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">强化学习</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">机器学习</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"><span class="level-start"><span class="level-item">自然语言处理</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E9%80%9F%E9%80%92/"><span class="level-start"><span class="level-item">论文速递</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-02-16T13:48:39.000Z">2023-02-16</time></p><p class="title"><a href="/2023/02/16/%E3%80%90%E8%AE%BA%E6%96%87%E3%80%91Knowledge-augmented-Frame-Semantic-Parsing-with-Hybrid-Prompt-tuning/">【论文】Knowledge-augmented Frame Semantic Parsing with Hybrid Prompt-tuning</a></p><p class="categories"><a href="/categories/%E8%AE%BA%E6%96%87%E9%80%9F%E9%80%92/">论文速递</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-01-20T13:49:04.000Z">2023-01-20</time></p><p class="title"><a href="/2023/01/20/%E5%A6%82%E4%BD%95%E4%BF%AE%E6%AD%A3%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%94%99%E8%AF%AF%E4%BF%A1%E5%BF%B5/">如何修正大模型的错误信念</a></p><p class="categories"><a href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-01-12T02:43:22.000Z">2023-01-12</time></p><p class="title"><a href="/2023/01/12/%E4%BB%80%E4%B9%88%E6%98%AF%E5%BC%BA%E5%A4%A7%E7%9A%84In-Context-Learning/">什么是强大的In-Context Learning</a></p><p class="categories"><a href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-01-10T11:09:27.000Z">2023-01-10</time></p><p class="title"><a href="/2023/01/10/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E4%B9%8B%E8%B7%AF%EF%BC%9A%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0-%E6%80%9D%E7%BB%B4%E9%93%BE/">大模型推理之路：提示学习+思维链</a></p><p class="categories"><a href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-11-13T08:12:10.000Z">2022-11-13</time></p><p class="title"><a href="/2022/11/13/%E8%B0%B7%E6%AD%8CLaMDA%E6%A8%A1%E5%9E%8B/">谷歌LaMDA模型</a></p><p class="categories"><a href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a></p></div></article></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="张睿 | 智能对话、AIGC、自然语言处理" height="28"></a><p class="is-size-7"><span>&copy; 2023 Rui Zhang</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© 2019</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>